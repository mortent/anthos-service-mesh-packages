apiVersion: v1
kind: ServiceAccount
metadata:
  name: istio-cni
  namespace: kube-system
  labels:
    app: istio-cni
    release: istio
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: istio-cni
  labels:
    app: istio-cni
    release: istio
rules:
  - resources:
      - pods
      - nodes
    apiGroups: [""]
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: istio-cni-repair-role
  labels:
    app: istio-cni
    release: istio
rules:
  - resources: ["pods"]
    apiGroups: [""]
    verbs: ["get", "list", "watch", "delete", "patch", "update"]
  - resources: ["events"]
    apiGroups: [""]
    verbs: ["get", "list", "watch", "delete", "patch", "update", "create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: istio-cni
  labels:
    app: istio-cni
    release: istio
roleRef:
  name: istio-cni
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
subjects:
  - name: istio-cni
    namespace: kube-system
    kind: ServiceAccount
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: istio-cni-repair-rolebinding
  labels:
    k8s-app: istio-cni-repair
roleRef:
  name: istio-cni-repair-role
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
subjects:
  - name: istio-cni
    namespace: kube-system
    kind: ServiceAccount
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: istio-cni-config
  namespace: kube-system
  labels:
    app: istio-cni
    release: istio
data:
  # The CNI network configuration to add to the plugin chain on each node.  The special
  # values in this config will be automatically populated.
  cni_network_config: |-
    {
      "cniVersion": "0.3.1",
      "name": "istio-cni",
      "type": "istio-cni",
      "log_level": "info",
      "kubernetes": {
          "kubeconfig": "__KUBECONFIG_FILEPATH__",
          "cni_bin_dir": "/home/kubernetes/bin",
          "exclude_namespaces": [ "istio-system", "kube-system" ]
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: istio-cni-node
  namespace: kube-system
  labels:
    k8s-app: istio-cni-node
    release: istio
spec:
  selector:
    matchLabels:
      k8s-app: istio-cni-node
  template:
    metadata:
      labels:
        k8s-app: istio-cni-node
        sidecar.istio.io/inject: "false"
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
        sidecar.istio.io/inject: "false"
    spec:
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 5
      serviceAccountName: istio-cni
      hostNetwork: true
      priorityClassName: system-cluster-critical
      nodeSelector:
        kubernetes.io/os: linux
      containers:
        # This container installs the Istio CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: "IMAGE_HUB/install-cni:IMAGE_TAG" # kpt-set: ${anthos.servicemesh.hub}/install-cni:${anthos.servicemesh.tag}
          command: ["install-cni"]
          env:
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: istio-cni-config
                  key: cni_network_config
            - name: CNI_NET_DIR
              value: /etc/cni/net.d
            # Deploy as a standalone CNI plugin or as chained?
            - name: CHAINED_CNI_PLUGIN
              value: "true"
          volumeMounts:
            - name: cni-bin-dir
              mountPath: /host/opt/cni/bin
            - name: cni-net-dir
              mountPath: /host/etc/cni/net.d
          livenessProbe:
            httpGet:
              port: 8000
              path: /healthz
            initialDelaySeconds: 5
          readinessProbe:
            httpGet:
              port: 8000
              path: /readyz
        - name: repair-cni
          image: "IMAGE_HUB/install-cni:IMAGE_TAG" # kpt-set: ${anthos.servicemesh.hub}/install-cni:${anthos.servicemesh.tag}
          command: ["/opt/local/bin/istio-cni-repair"]
          env:
            - name: "REPAIR_NODE-NAME"
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: "REPAIR_LABEL-PODS"
              value: "true"
            # Set to true to enable pod deletion
            - name: "REPAIR_DELETE-PODS"
              value: "true"
            - name: "REPAIR_RUN-AS-DAEMON"
              value: "true"
            - name: "REPAIR_SIDECAR-ANNOTATION"
              value: "sidecar.istio.io/status"
            - name: "REPAIR_INIT-CONTAINER-NAME"
              value: "istio-validation"
            - name: "REPAIR_BROKEN-POD-LABEL-KEY"
              value: "cni.istio.io/uninitialized"
            - name: "REPAIR_BROKEN-POD-LABEL-VALUE"
              value: "true"
      volumes:
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /home/kubernetes/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
      tolerations:
        # Make sure istio-cni-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
